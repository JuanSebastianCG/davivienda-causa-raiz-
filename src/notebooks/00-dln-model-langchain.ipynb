{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from model import GPTIntentions, IntentionList, Intention, PQRType, PeticionesList\n",
    "from utils import GPTIntentionProcessor, FileManager\n",
    "from prompt import PROMPT\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = {\n",
    "    \"empresas\": \"Empresas 2da Línea\",\n",
    "    \"no_fraude\": \"No Fraude\",\n",
    "}\n",
    "\n",
    "base = \"empresas\"\n",
    "df = pd.read_excel(\"../../data/raw/Cifras Analitica.xlsx\", sheet_name=\"Cifras\")\n",
    "df = df.query(\n",
    "    f\"MESA == '{DATA[base]}' & PRODUCTO != '' & PRODUCTO != 0 & CANAL_ORIGEN == 'Clientes'\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/35 [00:00<?, ?it/s]2024-06-14 15:52:09,343 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-14 15:52:09,375 - INFO - Saving partial results after processing 10 rows\n",
      "2024-06-14 15:52:09,435 - INFO - Partial results saved to partial_results.xlsx\n",
      "Processing batches:   3%|▎         | 1/35 [00:02<01:29,  2.64s/it]2024-06-14 15:52:12,875 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:   6%|▌         | 2/35 [00:06<01:43,  3.15s/it]2024-06-14 15:52:15,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:   9%|▊         | 3/35 [00:09<01:37,  3.05s/it]2024-06-14 15:52:19,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  11%|█▏        | 4/35 [00:12<01:37,  3.13s/it]2024-06-14 15:52:22,466 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  14%|█▍        | 5/35 [00:15<01:38,  3.29s/it]2024-06-14 15:52:25,550 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-14 15:52:25,553 - INFO - Saving partial results after processing 60 rows\n",
      "2024-06-14 15:52:25,635 - INFO - Partial results saved to partial_results.xlsx\n",
      "Processing batches:  17%|█▋        | 6/35 [00:18<01:31,  3.17s/it]2024-06-14 15:52:28,672 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  20%|██        | 7/35 [00:21<01:28,  3.14s/it]2024-06-14 15:52:32,133 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  23%|██▎       | 8/35 [00:25<01:27,  3.25s/it]2024-06-14 15:52:35,078 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  26%|██▌       | 9/35 [00:28<01:21,  3.15s/it]2024-06-14 15:52:37,815 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  29%|██▊       | 10/35 [00:31<01:15,  3.01s/it]2024-06-14 15:52:40,326 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-14 15:52:40,388 - INFO - Saving partial results after processing 110 rows\n",
      "2024-06-14 15:52:40,524 - INFO - Partial results saved to partial_results.xlsx\n",
      "Processing batches:  31%|███▏      | 11/35 [00:33<01:09,  2.92s/it]2024-06-14 15:52:43,587 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  34%|███▍      | 12/35 [00:36<01:08,  2.98s/it]2024-06-14 15:52:46,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  37%|███▋      | 13/35 [00:39<01:05,  2.96s/it]2024-06-14 15:52:48,873 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  40%|████      | 14/35 [00:42<00:58,  2.78s/it]2024-06-14 15:52:51,252 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  43%|████▎     | 15/35 [00:44<00:53,  2.66s/it]2024-06-14 15:52:53,885 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-14 15:52:53,890 - INFO - Saving partial results after processing 160 rows\n",
      "2024-06-14 15:52:54,150 - INFO - Partial results saved to partial_results.xlsx\n",
      "Processing batches:  46%|████▌     | 16/35 [00:47<00:51,  2.72s/it]2024-06-14 15:52:56,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  49%|████▊     | 17/35 [00:49<00:47,  2.66s/it]2024-06-14 15:52:59,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  51%|█████▏    | 18/35 [00:52<00:46,  2.76s/it]2024-06-14 15:53:02,836 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  54%|█████▍    | 19/35 [00:56<00:46,  2.90s/it]2024-06-14 15:53:05,511 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  57%|█████▋    | 20/35 [00:58<00:42,  2.83s/it]2024-06-14 15:53:08,255 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-14 15:53:08,315 - INFO - Saving partial results after processing 210 rows\n",
      "2024-06-14 15:53:08,542 - INFO - Partial results saved to partial_results.xlsx\n",
      "Processing batches:  60%|██████    | 21/35 [01:01<00:40,  2.88s/it]2024-06-14 15:53:11,758 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  63%|██████▎   | 22/35 [01:05<00:38,  3.00s/it]2024-06-14 15:53:14,513 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  66%|██████▌   | 23/35 [01:07<00:35,  2.92s/it]2024-06-14 15:53:17,233 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  69%|██████▊   | 24/35 [01:10<00:31,  2.86s/it]2024-06-14 15:53:20,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  71%|███████▏  | 25/35 [01:13<00:29,  2.93s/it]2024-06-14 15:53:22,858 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-14 15:53:22,919 - INFO - Saving partial results after processing 260 rows\n",
      "2024-06-14 15:53:23,255 - INFO - Partial results saved to partial_results.xlsx\n",
      "Processing batches:  74%|███████▍  | 26/35 [01:16<00:26,  2.91s/it]2024-06-14 15:53:26,580 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  77%|███████▋  | 27/35 [01:19<00:24,  3.05s/it]2024-06-14 15:53:29,385 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  80%|████████  | 28/35 [01:22<00:20,  2.98s/it]2024-06-14 15:53:32,464 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  83%|████████▎ | 29/35 [01:25<00:18,  3.01s/it]2024-06-14 15:53:34,636 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  86%|████████▌ | 30/35 [01:27<00:13,  2.76s/it]2024-06-14 15:53:37,564 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-06-14 15:53:37,615 - INFO - Saving partial results after processing 310 rows\n",
      "2024-06-14 15:53:37,937 - INFO - Partial results saved to partial_results.xlsx\n",
      "Processing batches:  89%|████████▊ | 31/35 [01:31<00:11,  2.90s/it]2024-06-14 15:53:40,895 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  91%|█████████▏| 32/35 [01:34<00:08,  2.94s/it]2024-06-14 15:53:43,524 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  94%|█████████▍| 33/35 [01:36<00:05,  2.85s/it]2024-06-14 15:53:46,560 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches:  97%|█████████▋| 34/35 [01:39<00:02,  2.90s/it]2024-06-14 15:53:50,197 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Processing batches: 100%|██████████| 35/35 [01:43<00:00,  2.96s/it]\n",
      "2024-06-14 15:53:50,671 - INFO - DataFrame saved to ../../results/empresas_abril_v14-06-24.xlsx\n"
     ]
    }
   ],
   "source": [
    "model = GPTIntentions(pydantic_object=IntentionList, prompt=PROMPT)\n",
    "processor = GPTIntentionProcessor(model, batch_size=10)\n",
    "processor.process_batches(\n",
    "    df, description_column=\"DESCRIPCION\", column_category=\"MOTIVO\", save_interval=50\n",
    ")\n",
    "df_concat = processor.generate_output_dataframe(df)\n",
    "FileManager.save_to_excel(df_concat, f\"../../results/{base}_abril_v14-06-24.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causa-raiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
